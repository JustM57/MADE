{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b828263-ea0f-4394-9b01-ee3e6417e2d6",
   "metadata": {},
   "source": [
    "# Академия MADE\n",
    "## Курс компьютерного зрения\n",
    "### Семинар 2: реализация ResNet\n",
    "\n",
    "#### План\n",
    "1. (Recap) Рутина обучения в PyTorch\n",
    "2. Реализация простой сети типа ResNet\n",
    "3. Проверка эффекта от BatchNormalization\n",
    "4. Проверка эффекта от residual-блоков\n",
    "5. ДЗ для любознательных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee8df98-d79b-47b8-8e41-34269ef0f9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "from torch.optim import Adam\n",
    "from torch.nn.functional import cross_entropy, relu\n",
    "\n",
    "from utils import plot, show_kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd033381-342e-4fe7-83bf-ac7982effff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST: 1x28x28\n",
    "# DATASET = \"MNIST\"\n",
    "\n",
    "# CIFAR10: 3x32x32\n",
    "DATASET = \"CIFAR10\"\n",
    "\n",
    "# DEVICE = \"cpu\"\n",
    "DEVICE = \"cuda:0\"\n",
    "\n",
    "NUM_EPOCHS = 2\n",
    "BATCH_SIZE = 256\n",
    "LR = 3e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5819e3e7-db88-4f19-a266-3f63cc09c686",
   "metadata": {},
   "source": [
    "Получим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aca3a23-c307-49e7-869a-923e5e91c035",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(0.5, 0.25, inplace=True),\n",
    "])\n",
    "\n",
    "if DATASET == \"MNIST\":\n",
    "    IMAGE_CHANNELS = 1\n",
    "    NUM_CLASSES = 10\n",
    "    dataset = MNIST(\"./dataset/mnist\", download=True, transform=transforms)\n",
    "elif DATASET == \"CIFAR10\":\n",
    "    IMAGE_CHANNELS = 3\n",
    "    NUM_CLASSES = 10\n",
    "    dataset = CIFAR10(\"./dataset/cifar\", download=True, transform=transforms)\n",
    "else:\n",
    "    raise NotImplementedError(DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b81a4b0-e74d-4c01-a75e-ced5da1f595d",
   "metadata": {},
   "source": [
    "#### (Recap) Рутина обучения в PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97ed23c-f3d3-452b-8a45-97856a1e3b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset=dataset, num_epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, lr=LR, device=DEVICE):\n",
    "    \"\"\"Model training routine function. \n",
    "    Uses Adam optimizer & cross-entropy loss.\n",
    "    \n",
    "    Args:\n",
    "        model: torch.nn.Module\n",
    "        dataset: torch.utils.data.Dataset\n",
    "        num_epochs: int\n",
    "        batch_size: int\n",
    "        lr: float\n",
    "        device: str\n",
    "        \n",
    "    Returns:\n",
    "        losses: list of float values of length num_epochs * len(dataloader)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # dataloader = # YOUR CODE HERE \n",
    "    # optimizer = # YOUR CODE HERE \n",
    "    \n",
    "    losses = []    \n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in tqdm.tqdm(dataloader):\n",
    "            xs, ys_true = batch\n",
    "            \n",
    "            # logits_pred = # YOUR CODE HERE \n",
    "            # loss = # YOUR CODE HERE \n",
    "            \n",
    "            # optimization step\n",
    "            # YOUR CODE HERE\n",
    "                                \n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cbb8b9-d573-49dd-9d5f-63e93c16b816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTS for train()\n",
    "\n",
    "input_size = dataset[0][0].size()\n",
    "fc = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(np.prod(input_size), NUM_CLASSES)\n",
    ")\n",
    "losses_fc = train(fc, dataset, num_epochs=1)\n",
    "\n",
    "assert len(losses_fc) == len(dataset) // BATCH_SIZE\n",
    "assert np.mean(losses_fc[:10]) > np.mean(losses_fc[-10:])\n",
    "\n",
    "plot(losses_fc, \"fc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8823fc3d-f131-4e29-b52d-639e2e155cce",
   "metadata": {},
   "source": [
    "#### Реализация простой сети типа ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e932676-561e-4dfb-9dfd-852defb8fdbb",
   "metadata": {},
   "source": [
    "Взглянем на примерную схему сети ResNet34:\n",
    "\n",
    "![resnet34](res/resnet34.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b018d418-6c15-424e-8576-118035b640fc",
   "metadata": {},
   "source": [
    "Реализуем свой \"ResNet10\":\n",
    "\n",
    "![resnet10](res/resnet10.png)\n",
    "\n",
    "Пересчитайте число слоев с весами - их как раз 10.\n",
    "\n",
    "Кроме того, для простоты все операции уменьшения размера сведем к пулингу и вынесем в отдельные слои (а не встроим в сами сверточные блоки, как, например, в [torchvision](https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83960262-e713-43f9-88de-1caad2bd2bb8",
   "metadata": {},
   "source": [
    "Для начала реализуем вспомогательную функцию `get_conv(...)`, которая приготовит нам последовательность (свертка + активация + батчнорм). Это очень распространенная комбинация операций, которая на будет нужна неоднократно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aa8389-cd0c-4f98-9ab6-abde4fdfc26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv(kernel_size, in_features, out_features, with_bn=True, with_relu=True):\n",
    "    \"\"\"Create conv -> [relu] -> [bn] layers, embedded in torch.nn.Sequential module.\n",
    "    \n",
    "    ! Conv layer must preserve spatial tensor dims (i.e. apply zero padding).\n",
    "    \n",
    "    Args:\n",
    "        kernel_size: int\n",
    "        in_features: int\n",
    "        out_features: int\n",
    "        with_bn: bool\n",
    "        with_relu: bool\n",
    "        \n",
    "    Returns:\n",
    "        torch.nn.Sequential\n",
    "    \"\"\"\n",
    "    layers = [\n",
    "        # nn.Conv2d(... # YOUR CODE HERE\n",
    "    ]\n",
    "    \n",
    "    if with_relu:\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "    if with_bn:\n",
    "        # YOUR CODE HERE\n",
    "    \n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b56c194-254d-4379-ac84-d200d1b2b8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTS for get_conv()\n",
    "conv = get_conv(3, 8, 16)\n",
    "\n",
    "assert len(conv) == 3\n",
    "assert isinstance(conv[0], torch.nn.Conv2d)\n",
    "assert conv[0].in_channels == 8\n",
    "assert conv[0].out_channels == 16\n",
    "\n",
    "assert isinstance(conv[1], torch.nn.ReLU)\n",
    "\n",
    "assert isinstance(conv[2], torch.nn.BatchNorm2d)\n",
    "assert conv[2].num_features == 16\n",
    "\n",
    "\n",
    "conv = get_conv(3, 8, 16, with_bn=False, with_relu=False)\n",
    "\n",
    "assert len(conv) == 1\n",
    "assert isinstance(conv[0], torch.nn.Conv2d)\n",
    "assert conv[0].in_channels == 8\n",
    "assert conv[0].out_channels == 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224a694b-b778-4714-8262-4a86467ed7b7",
   "metadata": {},
   "source": [
    "Также реализуем слой `GlobalAveragePooling`. Помните, зачем он нужен?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4741a780-218f-45f1-bc57-19871d620832",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalAveragePooling2d(nn.Module):\n",
    "    def forward(self, x):\n",
    "        \"\"\"GAP forward pass.\n",
    "        \n",
    "        Args:\n",
    "            x: torch.Tensor, size B x C x H x W.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor, size B x C.\n",
    "        \"\"\"\n",
    "        # y = # YOUR CODE HERE\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a41766-4ede-4944-8ace-c09732e87a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTS for GAP\n",
    "\n",
    "gap = GlobalAveragePooling2d()\n",
    "x = torch.randn(4, 3, 16, 16)\n",
    "y = gap(x)\n",
    "\n",
    "assert y.size() == (4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b3a3ef-ae94-46e5-a93f-3d10e14c6f59",
   "metadata": {},
   "source": [
    "Перейдем к главному в ResNet - собственно, residual-блоку:\n",
    "\n",
    "![residual_block](res/residual_block.png)\n",
    "\n",
    "Под \"блоком\" мы будем иметь в виду последовательность сверточных слоев (с активацией и BN), \"вокруг\" которых прокинут skip-connection. Таким образом, в нашей сети \"ResNet10\" будет 4 таких блока (найдите их на картинке c ResNet10 выше).\n",
    "\n",
    "Важный момент: обратите внимание, что тензоры **x** и **F(x)** могут иметь разное число каналов (например, 64 и 128). Как же сложить два таких тензора?..\n",
    "\n",
    "Ответ: сделать \"проекцию\", см. `projection` в коде."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d351646-d5db-4874-aa45-c5d8ecb9203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, num_input_features, num_features, num_layers, with_bn=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        if num_input_features != num_features:\n",
    "            self.projection = nn.Conv2d(num_input_features, num_features, 1, 1, 0)\n",
    "        else:\n",
    "            self.projection = None\n",
    "        \n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            conv = get_conv(3, num_input_features, num_features, with_bn=with_bn)\n",
    "            layers.append(conv)\n",
    "            num_input_features = num_features\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "        self.num_input_features = num_input_features\n",
    "        self.num_features = num_features\n",
    "        self.num_layers = num_layers\n",
    "        self.with_bn = with_bn\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass.\n",
    "        Applies convolution layers and skip-connection; self.projection, if necessary.\n",
    "        \n",
    "        Args:\n",
    "            x: torch.Tensor, size B x C x H x W.\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor, size B x C x H x W.\n",
    "        \"\"\"\n",
    "        x_input = x\n",
    "        # YOUR CODE HERE\n",
    "    \n",
    "        return relu(x)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        out = f\"ResidualBlock(num_input_features={self.num_input_features}, num_features={self.num_features}, num_layers={self.num_layers}, with_bn={self.with_bn})\"\n",
    "        for l in self.layers:\n",
    "            out += \"\\n\" + \"\\t\" + repr(l)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f8f2f3-17f2-4f53-a914-160e6314f744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTS for ResidualBlock\n",
    "block = ResidualBlock(4, 4, 2)\n",
    "\n",
    "assert len(block.layers) == 2\n",
    "assert len(block.layers[0]) == 3\n",
    "assert len(block.layers[1]) == 3\n",
    "assert isinstance(block.layers[1][2], nn.BatchNorm2d)\n",
    "\n",
    "print(block)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09efc02b-f4f6-46a2-86df-336e61fa8be3",
   "metadata": {},
   "source": [
    "Дальше дело за малым - собрать из готовых блоков нашу сеть:\n",
    "\n",
    "![resnet10](res/resnet10.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa5aec0-062c-4474-9876-5c4fff5ef96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resnet10(num_input_features=3, num_classes=10, with_bn=True):\n",
    "    pool = nn.MaxPool2d((2, 2))\n",
    "    gap = GlobalAveragePooling2d()\n",
    "    fc = nn.Linear(512, num_classes)\n",
    "    return nn.Sequential(\n",
    "        get_conv(7, num_input_features, 64, with_bn=with_bn),\n",
    "        pool,\n",
    "        ResidualBlock(64, 64, 2, with_bn=with_bn),\n",
    "        pool,\n",
    "        ResidualBlock(64, 128, 2, with_bn=with_bn),\n",
    "        pool,\n",
    "        ResidualBlock(128, 256, 2, with_bn=with_bn),\n",
    "        pool,\n",
    "        ResidualBlock(256, 512, 2, with_bn=with_bn),\n",
    "        gap,\n",
    "        fc\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf666bd-64dc-4c05-a300-55c75f43b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet10 = create_resnet10()\n",
    "resnet10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514797d5-b79c-4ee4-8667-12fd7e1a229f",
   "metadata": {},
   "source": [
    "Обучим полученную модель с помощью реализованной в начале функции `train()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7f0ae-2ba0-4e93-b16e-1f429b51b9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_resnet10 = train(resnet10, device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a7f136-7774-4575-b60c-b56b562f7831",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(losses_resnet10, label=\"resnet10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296a3065-42d2-4944-adb5-e11a57f6afd5",
   "metadata": {},
   "source": [
    "#### Проверка эффекта от BatchNormalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb573b7-d7e1-4a2f-b56e-4584fb58f146",
   "metadata": {},
   "source": [
    "Теперь проведем небольшой эксперимент: создадим сеть с аналогичной нашему ResNet10 архитектурой, но без слоев BatchNormalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8698ca43-33c6-4729-9bcb-6bcf507c9f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet10_nobn = create_resnet10(with_bn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ba29a2-3af7-4a68-bb64-37881cd84513",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_resnet10_nobn = train(resnet18_nobn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb1029d-6da9-449e-b87b-8bd5211dc427",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(losses_resnet10, label=\"resnet10_bn\")\n",
    "plot(losses_resnet10_nobn, label=\"resnet10_nobn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357c3b7b-ed47-4dc7-a68f-2ef706b5d402",
   "metadata": {},
   "source": [
    "#### Проверка эффекта от Residual-блоков\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fad0f6-fecd-49b7-b8be-61418f2055bd",
   "metadata": {},
   "source": [
    "Теперь построим модель, у которой будет аналогичное число параметров (и FLOPS), но у которой не будет skip-connections. Называться она будет... Net10?\n",
    "\n",
    "Для этого напишем класс для обычного блока - это легко сделать, ощипав уже написанный класс `ResidualBlock` (да, все вот так наоборот)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1530e61-67fc-4cfd-a432-72c44e9ef4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, num_input_features, num_features, num_layers, with_bn=True):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            conv = get_conv(3, num_input_features, num_features, with_bn=with_bn)\n",
    "            layers.append(conv)\n",
    "            num_input_features = num_features\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "        self.num_input_features = num_input_features\n",
    "        self.num_features = num_features\n",
    "        self.num_layers = num_layers\n",
    "        self.with_bn = with_bn\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        out = f\"Block(num_input_features={self.num_input_features}, num_features={self.num_features}, num_layers={self.num_layers}, with_bn={self.with_bn})\"\n",
    "        for l in self.layers:\n",
    "            out += \"\\n\" + \"\\t\" + repr(l)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836adaf1-cd19-4aed-9d1a-d0207da13eea",
   "metadata": {},
   "source": [
    "Функция для создания модели - тоже аналогична:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f0cda-6772-4b8b-8fb8-25d593d3dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_net10(num_input_features=IMAGE_CHANNELS, num_classes=NUM_CLASSES, with_bn=True):\n",
    "    pool = nn.MaxPool2d((2, 2))\n",
    "    gap = GlobalAveragePooling2d()\n",
    "    fc = nn.Linear(512, num_classes)\n",
    "    return nn.Sequential(\n",
    "        get_conv(7, num_input_features, 64, with_bn=with_bn),\n",
    "        pool,\n",
    "        Block(64, 64, 2, with_bn=with_bn),\n",
    "        pool,\n",
    "        Block(64, 128, 2, with_bn=with_bn),\n",
    "        pool,\n",
    "        Block(128, 256, 2, with_bn=with_bn),\n",
    "        pool,\n",
    "        Block(256, 512, 2, with_bn=with_bn),\n",
    "        gap,\n",
    "        fc\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cce5ca7-8b9c-4e56-8f9e-01bcdc74d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "net10 = create_net10()\n",
    "net10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba45b91d-1f74-4509-9bae-b5d1ed1320c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_net10 = train(net10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13dc210-8717-40b7-b8b8-400d19dc1654",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(losses_resnet10, label=\"resnet10\")\n",
    "plot(losses_net10, label=\"net10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c51f1d-f57e-4833-b660-d893f9686ce9",
   "metadata": {},
   "source": [
    "При обучении данных моделей разницы почти не видно... Почему?\n",
    "\n",
    "Ок, сделаем сети поглубже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d801d2e-07bf-44f8-a178-2fbfddc57a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_net34(num_input_features=IMAGE_CHANNELS, num_classes=NUM_CLASSES, with_bn=True):\n",
    "    pool = nn.MaxPool2d((2, 2))\n",
    "    gap = GlobalAveragePooling2d()\n",
    "    fc = nn.Linear(512, num_classes)\n",
    "    return nn.Sequential(\n",
    "        get_conv(7, num_input_features, 64, with_bn=with_bn),\n",
    "        pool,\n",
    "        Block(64, 64, 2, with_bn=with_bn),\n",
    "        Block(64, 64, 2, with_bn=with_bn),\n",
    "        Block(64, 64, 2, with_bn=with_bn),\n",
    "        pool,\n",
    "        Block(64, 128, 2, with_bn=with_bn),\n",
    "        Block(128, 128, 2, with_bn=with_bn),\n",
    "        Block(128, 128, 2, with_bn=with_bn),\n",
    "        pool,\n",
    "        Block(128, 256, 2, with_bn=with_bn),\n",
    "        Block(256, 256, 2, with_bn=with_bn),\n",
    "        Block(256, 256, 2, with_bn=with_bn),\n",
    "        Block(256, 256, 2, with_bn=with_bn),\n",
    "        Block(256, 256, 2, with_bn=with_bn),\n",
    "        pool,\n",
    "        Block(256, 512, 2, with_bn=with_bn),\n",
    "        Block(512, 512, 2, with_bn=with_bn),\n",
    "        Block(512, 512, 2, with_bn=with_bn),\n",
    "        gap,\n",
    "        fc\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cc6472-add1-4b6f-afd8-7a5aad9d7ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resnet34(num_input_features=IMAGE_CHANNELS, num_classes=NUM_CLASSES, with_bn=True):\n",
    "    pool = nn.MaxPool2d((2, 2))\n",
    "    gap = GlobalAveragePooling2d()\n",
    "    fc = nn.Linear(512, num_classes)\n",
    "    return nn.Sequential(\n",
    "        get_conv(7, num_input_features, 64, with_bn=with_bn),\n",
    "        pool,\n",
    "        ResidualBlock(64, 64, 2, with_bn=with_bn),\n",
    "        ResidualBlock(64, 64, 2, with_bn=with_bn),\n",
    "        ResidualBlock(64, 64, 2, with_bn=with_bn),\n",
    "        pool,\n",
    "        ResidualBlock(64, 128, 2, with_bn=with_bn),\n",
    "        ResidualBlock(128, 128, 2, with_bn=with_bn),\n",
    "        ResidualBlock(128, 128, 2, with_bn=with_bn),\n",
    "        pool,\n",
    "        ResidualBlock(128, 256, 2, with_bn=with_bn),\n",
    "        ResidualBlock(256, 256, 2, with_bn=with_bn),\n",
    "        ResidualBlock(256, 256, 2, with_bn=with_bn),\n",
    "        ResidualBlock(256, 256, 2, with_bn=with_bn),\n",
    "        ResidualBlock(256, 256, 2, with_bn=with_bn),\n",
    "        pool,\n",
    "        ResidualBlock(256, 512, 2, with_bn=with_bn),\n",
    "        ResidualBlock(512, 512, 2, with_bn=with_bn),\n",
    "        ResidualBlock(512, 512, 2, with_bn=with_bn),\n",
    "        gap,\n",
    "        fc\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eecbc25-81ab-44b4-8fda-166515b081fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "net34 = create_net34()\n",
    "net34;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ada3f5-4646-489d-b134-af5303d31da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_net34 = train(net34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26014f73-120c-4790-9322-00685a66e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34 = create_resnet34()\n",
    "resnet34;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bb9f14-e01c-4b1f-86ea-a5fd047593eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_resnet34 = train(resnet34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0fcee6-7987-4f66-9728-c43454f54518",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(losses_resnet34, \"resnet34\")\n",
    "plot(losses_net34, \"net34\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f267ba7-e176-440b-960d-51102cdf5633",
   "metadata": {},
   "source": [
    "Gotcha!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09042d36-93d8-4810-b4f2-a83004ce0660",
   "metadata": {},
   "source": [
    "#### (Bonus) Свертки первого слоя"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c2f105-f5d4-451e-884f-14ce4842dc7c",
   "metadata": {},
   "source": [
    "Возьмем ResNet18, предобученный (долго и качественно, в отличие от наших поделок) на датасете ImageNet и отрисуем ядра сверток первого сверточного слоя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcce155-93be-4e47-aaea-1a7ab1a4b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "resnet18_pt = resnet18(pretrained=True)\n",
    "show_kernels(resnet18_pt.conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ac8c6-514e-4236-b023-d9dab7f562c0",
   "metadata": {},
   "source": [
    "#### Для любознательных\n",
    "\n",
    "* Поучите сети подольше. Как соотносятся итоговые результаты с residual-блоками и без? С BN и без?\n",
    "* Мы замеряли только train loss. Попробуйте замерить другие метрики, использовать validation set, ...\n",
    "* Реализуйте SEBlock (Squeeze-n-Excitation), а затем соберите (с помощью кода из этого семинара) SE-Net. Как она себя ведет?\n",
    "* Реализуйте Bottleneck для ResNet50/101/152. Подсмотреть можно [тут](https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
